import numpy as np
from pydataset import data
import pandas as pd
import numpy
from sklearn.linear_model import LogisticRegression
from sklearn.model_selection import train_test_split


titanic = data('titanic')
sample = titanic.sample(5)

# Feature engineering
titanic = pd.get_dummies(titanic, drop_first=True)
one_hot_encoded = titanic.sample(5)
#print(one_hot_encoded)

# Test Train Split
X_train, X_test, y_train, y_test = train_test_split(titanic.drop('survived_yes', axis=1), titanic['survived_yes'])

# Train the model using the training data
LogReg = LogisticRegression(solver='lbfgs')
LogReg.fit(X_train, y_train)

# predicting if a class-1, child_age, girl survived
c1cf = LogReg.predict(np.array([[0,0,1,1]]))[0]
print(c1cf)

# predicting if a class-3, adult_age, male survived
c3am = LogReg.predict(np.array([[0,1,0,0]]))[0]
print(c3am)

score = LogReg.score(X_test, y_test)
print(score)

# Understand score
prediction = (LogReg.predict(X_test)>.5).astype(int)
cal_score = np.sum(prediction==y_test)/len((y_test))

print(cal_score)


